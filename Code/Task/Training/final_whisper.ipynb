{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbeed3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\follo\\anaconda3\\envs\\GPU\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import (\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperProcessor,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "from transformers.models.whisper.feature_extraction_whisper import WhisperFeatureExtractor\n",
    "from transformers.models.whisper.tokenization_whisper import WhisperTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233d3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/whisper-tiny\"\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "feature_extractor = processor.feature_extractor\n",
    "tokenizer = processor.tokenizer\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eada540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 22488\n",
      "Validation size: 2811\n",
      "Test size: 2812\n"
     ]
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"Dataset/train.csv\",\n",
    "    \"validation\": \"Dataset/val.csv\",\n",
    "    \"test\": \"Dataset/test.csv\"\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "val_ds   = dataset[\"validation\"]\n",
    "test_ds  = dataset[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_ds))\n",
    "print(\"Validation size:\", len(val_ds))\n",
    "print(\"Test size:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b89f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    # Загружаем wav\n",
    "    waveform, sr = torchaudio.load(batch[\"path\"])\n",
    "    waveform = waveform.mean(dim=0).numpy()  # моно\n",
    "\n",
    "    # Приводим к 16kHz\n",
    "    if sr != 16000:\n",
    "        waveform = torchaudio.functional.resample(\n",
    "            torch.tensor(waveform), sr, 16000\n",
    "        ).numpy()\n",
    "\n",
    "    # Прогоняем через WhisperProcessor\n",
    "    inputs = processor(\n",
    "        waveform,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    labels = processor.tokenizer(\n",
    "        batch[\"text\"],\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "\n",
    "    batch[\"input_features\"] = inputs.input_features[0]\n",
    "    batch[\"labels\"] = labels[0]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00c8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем препроцессинг ко всем сплитам\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds   = val_ds.map(preprocess)\n",
    "test_ds  = test_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2d1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    \"\"\"\n",
    "    Коллатор специально для Whisper: делает padding\n",
    "    и для input_features, и для labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # входные признаки (мел-спектрограммы)\n",
    "        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            input_features,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # текстовые метки\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            label_features,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # заменяем паддинг на -100 для PyTorch loss\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1), -100\n",
    "        )\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09788a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcdf43c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\follo\\AppData\\Local\\Temp\\ipykernel_10596\\2510436567.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 05:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.679500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.187200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.188000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=3.6211781311035156, metrics={'train_runtime': 311.3659, 'train_samples_per_second': 2.569, 'train_steps_per_second': 0.321, 'total_flos': 1.9695108096e+16, 'train_loss': 3.6211781311035156, 'epoch': 0.03557452863749555})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper_finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    max_steps=100,  # маленький датасет\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # processing_class=processor  # можно использовать для скрытия FutureWarning\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d29869f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 09:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2308405637741089, 'eval_runtime': 601.1059, 'eval_samples_per_second': 4.676, 'eval_steps_per_second': 0.586, 'epoch': 0.03557452863749555}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(val_ds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656a84e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.save_pretrained(\"./whisper_finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
