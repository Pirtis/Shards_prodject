{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbeed3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\follo\\anaconda3\\envs\\GPU\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import (\n",
    "    WhisperForConditionalGeneration,\n",
    "    WhisperProcessor,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "from transformers.models.whisper.feature_extraction_whisper import WhisperFeatureExtractor\n",
    "from transformers.models.whisper.tokenization_whisper import WhisperTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/whisper-tiny\"\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "feature_extractor = processor.feature_extractor\n",
    "tokenizer = processor.tokenizer\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eada540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 220901 examples [00:00, 276756.33 examples/s]\n",
      "Generating validation split: 27613 examples [00:00, 270656.22 examples/s]\n",
      "Generating test split: 27613 examples [00:00, 276069.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 220901\n",
      "Validation size: 27613\n",
      "Test size: 27613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": r\"E:\\Education\\4 course 1 semester\\Course project\\Shards_prodject\\Code\\Task\\Dataset\\train.csv\",\n",
    "    \"validation\": r\"E:\\Education\\4 course 1 semester\\Course project\\Shards_prodject\\Code\\Task\\Dataset\\val.csv\",\n",
    "    \"test\": r\"E:\\Education\\4 course 1 semester\\Course project\\Shards_prodject\\Code\\Task\\Dataset\\test.csv\"\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "val_ds   = dataset[\"validation\"]\n",
    "test_ds  = dataset[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_ds))\n",
    "print(\"Validation size:\", len(val_ds))\n",
    "print(\"Test size:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b89f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    \n",
    "    waveform, sr = torchaudio.load(batch[\"path\"])\n",
    "    waveform = waveform.mean(dim=0).numpy() \n",
    "\n",
    "\n",
    "    if sr != 16000:\n",
    "        waveform = torchaudio.functional.resample(\n",
    "            torch.tensor(waveform), sr, 16000\n",
    "        ).numpy()\n",
    "\n",
    "\n",
    "    inputs = processor(\n",
    "        waveform,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "\n",
    "    labels = processor.tokenizer(\n",
    "        batch[\"text\"],\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "\n",
    "\n",
    "    batch[\"input_features\"] = inputs.input_features[0]\n",
    "    batch[\"labels\"] = labels[0]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   3%|▎         | 6269/220901 [02:13<1:16:07, 46.99 examples/s] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You need to specify either `text` or `text_target`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Применяем препроцессинг ко всем сплитам\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m val_ds   \u001b[38;5;241m=\u001b[39m val_ds\u001b[38;5;241m.\u001b[39mmap(preprocess)\n\u001b[0;32m      4\u001b[0m test_ds  \u001b[38;5;241m=\u001b[39m test_ds\u001b[38;5;241m.\u001b[39mmap(preprocess)\n",
      "File \u001b[1;32mc:\\Users\\follo\\anaconda3\\envs\\GPU\\Lib\\site-packages\\datasets\\arrow_dataset.py:562\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    560\u001b[0m }\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 562\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\follo\\anaconda3\\envs\\GPU\\Lib\\site-packages\\datasets\\arrow_dataset.py:3341\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[0;32m   3339\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3340\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m unprocessed_kwargs \u001b[38;5;129;01min\u001b[39;00m unprocessed_kwargs_per_job:\n\u001b[1;32m-> 3341\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munprocessed_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcheck_if_shard_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3344\u001b[0m \u001b[38;5;66;03m# Avoids PermissionError on Windows (the error: https://github.com/huggingface/datasets/actions/runs/4026734820/jobs/6921621805)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\follo\\anaconda3\\envs\\GPU\\Lib\\site-packages\\datasets\\arrow_dataset.py:3673\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[0;32m   3671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[0;32m   3672\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 3673\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3674\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3675\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\follo\\anaconda3\\envs\\GPU\\Lib\\site-packages\\datasets\\arrow_dataset.py:3647\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[1;34m(shard_iterable)\u001b[0m\n\u001b[0;32m   3645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3647\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\follo\\anaconda3\\envs\\GPU\\Lib\\site-packages\\datasets\\arrow_dataset.py:3570\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[1;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[0;32m   3568\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[0;32m   3569\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m-> 3570\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Прогоняем через WhisperProcessor\u001b[39;00m\n\u001b[0;32m     13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(\n\u001b[0;32m     14\u001b[0m     waveform,\n\u001b[0;32m     15\u001b[0m     sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m,\n\u001b[0;32m     16\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m     24\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39minput_features[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     25\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m labels[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\follo\\anaconda3\\envs\\GPU\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2932\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2930\u001b[0m all_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2932\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either `text` or `text_target`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2934\u001b[0m     \u001b[38;5;66;03m# The context manager will send the inputs as normal texts and not text_target, but we shouldn't change the\u001b[39;00m\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;66;03m# input mode in this case.\u001b[39;00m\n\u001b[0;32m   2936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n",
      "\u001b[1;31mValueError\u001b[0m: You need to specify either `text` or `text_target`."
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds   = val_ds.map(preprocess)\n",
    "test_ds  = test_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "\n",
    "    def __call__(self, features):\n",
    "        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            input_features,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            label_features,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1), -100\n",
    "        )\n",
    "\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09788a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf43c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\follo\\AppData\\Local\\Temp\\ipykernel_10596\\2510436567.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 05:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.679500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.187200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.188000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=3.6211781311035156, metrics={'train_runtime': 311.3659, 'train_samples_per_second': 2.569, 'train_steps_per_second': 0.321, 'total_flos': 1.9695108096e+16, 'train_loss': 3.6211781311035156, 'epoch': 0.03557452863749555})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper_LoRA\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    max_steps=41000, \n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29869f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 09:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2308405637741089, 'eval_runtime': 601.1059, 'eval_samples_per_second': 4.676, 'eval_steps_per_second': 0.586, 'epoch': 0.03557452863749555}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(val_ds)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a238a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./whisper_LoRA\")      \n",
    "processor.save_pretrained(\"./whisper_LoRA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
